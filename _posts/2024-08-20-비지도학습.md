---
layout: single
title:  "비지도 학습"
---

## 5. 비지도 학습
### 5.1 군집 알고리즘
* 비지도 학습(unsupervised learning): data의 target이 없을 때 사용하는 머신러닝 알고리즘으로 패턴이나 구조를 발견할 때 사용된다.
* 비지도 학습의 종류: 군집(clustering), 차원 축소(PCA) 등
* 군집: 비슷한 샘플끼리 하나의 그룹으로 모으는 대표적인 비지도 학습
  * 군집 알고리즘으로 모은 샘플 그룹을 클러스터(cluster)라고 부른다.
<br>                   

### 과일 이미지 데이터로 군집 알고리즘 이해하기
```python
# 데이터 가져오기
!wget https://bit.ly/fruits_300_data -O fruits_300.npy

import numpy as np
import matplotlib.pyplot as plt

fruits = np.load('fruits_300.npy')

print(fruits.shape)
>>> (300, 100, 100)

print(fruits[0, 0, :])
>>>
[  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1
   2   2   2   2   2   2   1   1   1   1   1   1   1   1   2   3   2   1
   2   1   1   1   1   2   1   3   2   1   3   1   4   1   2   5   5   5
   19 148 192 117  28   1   1   2   1   4   1   1   3   1   1   1   1   1
   2   2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1    
   1   1   1   1   1   1   1   1   1   1 ]
```
* 해당 데이터셋은 kaggle에 공개된 사과, 바나나, 파인애플 흑백 사진 데이터다.
* 해당 데이터셋의 배열의 크기는 3차원이다.
* 첫 번재 차원(300)은 샘플의 개수를 의미한다.
* 두 번째 차원(100)은 이미지 높이를 의미한다.
* 세 번째 차원(100)은 이미지 너비를 의미한다.
* 따라서, 이미지 크기가 100 x 100인 과일 이미지 샘플이 300개 존재하는 것이다.
* 첫 번째 행에 있는 픽셀 100개 값의 출력 결과 해당 넘파이 배열은 흑백 사진을 담고 있어 0~255까지의 정숫값을 가지는 것을 알 수 있다.
<br>          

#### 과일 이미지 시각화 및 픽셀 분석
```python
# 원본 이미지
plt.imshow(fruits[0], cmap='gray')
plt.show()

# 흰색 검은색 반전 이미지
plt.imshow(fruits[0], cmap='gray_r')
plt.show()
```
![photo 61](/assets/img/blog/img61.png)
![photo 62](/assets/img/blog/img62.png)                       
* matplotlib의 imshow() 함수를 통해 넘파이 배열로 저장된 이미지를 쉽게 그릴 수 있다.
* imshow() 함수의 cmap 매개변수의 따라 그림이 달라질 수 있다.
  * cmap='gray' : 이미지를 흑백으로 나타내기 위한 설정
  * cmap='gray_r': 이미지를 흑백 반전으로 나타내기 위한 설정
    * 해당 그림의 경우 본래 검은 바탕에 사과 그림이 존재하나 흑백 반전을 통해 흰색 바탕에 사과 그림이 존재한다.
    * 'gray_r' 사용 이유: 다른 알고리즘에 사용될 때 픽셀값이 0이면 출력값도 0이 되어 의미가 없어진다. 픽셀값이 높아지면 출력값도 커지기 때문에 의미를 부여하기 좋아진다.
    * 픽셀값 0: 검은색 / 픽셀값 255: 흰색
    * 흑백 반전 시 흰색 바탕에 검은색 부분을 강조하여 사용할 수 있다.
* matplotlib의 subplots() 함수를 사용해 여러 개의 그래프를 배열처럼 그릴 수도 있다.
<br>           

#### 픽셀의 평균값을 이용한 시각화
```python
2차원 배열을 1차원으로 변경
apple = fruits[0:100].reshape(-1, 100*100)
pineapple = fruits[100:200].reshape(-1, 100*100)
banana = fruits[200:300].reshape(-1, 100*100)

# 과일 이미지 픽셀값의 평균값에 따른 시각화(히스토그램)
plt.hist(np.mean(apple, axis=1), alpha=0.8)
plt.hist(np.mean(pineapple, axis=1), alpha=0.8)
plt.hist(np.mean(banana, axis=1), alpha=0.8)
plt.legend(['apple', 'pineapple', 'banana'])
plt.show()
```
![photo 63](/assets/img/blog/img63.png)                   
* reshape() 메서드를 사용해 2차원의 이미지를 크기(100 x 100)를 1차원 배열(10,000)로 만든다. 첫 번째 차원을 -1로 지정하면 자동으로 남은 차원을 할당한다.
* 샘플의 픽셀 평균값을 계산해 히스토그램으로 시각화하면 과일에 따른 평균값의 분포를 알 수 있다.
  * axis=1: 열을 따라 계산한다.
  * axis=0: 행을 따라 계산한다.                     
    ![photo 66](/assets/img/blog/img66.png)                     
* 해당 히스토그램을 통해 평균값을 이용해 바나나는 구분해낼 수 있다.

### 픽셀별 평균값을 이용한 시각화
```python
# 픽셀별 평균값 시각화(1차원)
fig, axs = plt.subplots(1, 3, figsize=(20, 5))
axs[0].bar(range(10000), np.mean(apple, axis=0))
axs[1].bar(range(10000), np.mean(pineapple, axis=0))
axs[2].bar(range(10000), np.mean(banana, axis=0))
plt.show()

# 1차원 데이터를 2차원 데이터로 변경
apple_mean = np.mean(apple, axis=0).reshape(100, 100)
pineapple_mean = np.mean(pineapple, axis=0).reshape(100, 100)
banana_mean = np.mean(banana, axis=0).reshape(100, 100)

# 픽셀별 평균값 시각화(2차원)
fig, axs = plt.subplots(1, 3, figsize=(20, 5))
axs[0].imshow(apple_mean, cmap='gray_r')
axs[1].imshow(pineapple_mean, cmap='gray_r')
axs[2].imshow(banana_mean, cmap='gray_r')
plt.show()
```
![photo 64](/assets/img/blog/img64.png)                 
![photo 65](/assets/img/blog/img65.png)                          
* 픽셀별 평균값(axis=0)을 계산해 bar chart 형식으로 나타나면 다음과 같은 특징을 알 수 있다..
  * 사과는 사진 아래쪽으로 갈수록 값이 높아진다.
  * 파인애플은 비교적 값이 고르고 높다.
  * 바나나는 중앙의 픽셀값이 높다.
* reshape() 메서드를 이용해 1차원 배열을 2차원 배열로 변경하면 이미지 데이터로 시각화가 가능하다.
* 2차원 이미지 시각화를 통해 과일별 이미지의 특징을 파악할 수 있다.

#### 평균값에 따른 이미지 클러스터링
```python
abs_diff = np.abs(fruits - apple_mean)
abs_mean = np.mean(abs_diff, axis=(1,2))
print(abs_mean.shape)


apple_index = np.argsort(abs_mean)[:100]
fig, axs = plt.subplots(10, 10, figsize=(10,10))
for i in range(10):
    for j in range(10):
        axs[i, j].imshow(fruits[apple_index[i*10 + j]], cmap='gray_r')
        axs[i, j].axis('off')
plt.show()
```
![photo 67](/assets/img/blog/img67.png)             
* abs() 함수를 이용해 절댓값의 오차를 계산하고 평균값과 가까운 사진을 고르면 다음과 같은 결과가 나온다.
* 사과 사진 100개를 정확하게 고른 것을 알 수 있다.
* 이와 같이 비슷한 샘플끼리 그룹을 모으는 작업을 군집(clustering)이라고 한다.
* 하지만, 과일 이미지의 target 이름을 알고 있었기 때문에 완벽한 비지도 학습이라고 할 수는 없다.
<br>            

### 5.2 K-평균 군집 알고리즘
* K-Means 군집 알고리즘: 데이터를 K개의 군집으로 나누기 위해 각 데이터를 가장 가까운 군집 중심으로 할당하고, 군집 중심을 반복적으로 업데이트하여 군집을 최적화하는 비지도 학습 알고리즘이다.
* 클러스터 중심(cluster center) or 센트로이드(centroid): 클러스터의 평균값이 위한 곳을 의미한다.
* K-Means 알고리즘 작동 방식
  1. 무작위로 k개의 클러스터 중심을 정한다.
  2. 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스터의 샘플을 지정한다.
  3. 클러스터에 속한 샘플의 평균값으로 클러스터 중심을 변경한다.
  4. 클러스터 중심에 변화가 없을 때까지 2번으로 돌아가 반복한다.
  ![photo 68](/assets/img/blog/img68.png)             
* K-Means 알고리즘은 sklearn.cluster 모듈 아래 KMeans 클래스에 구현되어 있다.
* KMeans 매개변수
  * n_clusters: 클러스터의 개수를 지정한다. (기본값 8)
  * n_init: 반복 횟수 (기본값 10)
  * max_iter: 한 번의 실행에서 최적의 센트로이드를 찾기 위해 반복할 수 있는 최대 횟수(기본값 200)
<br>         

#### K-Meas 알고리즘을 이용한 클러스터링
```python
# 데이터 준비
!wget https://bit.ly/fruits_300_data -O fruits_300.npy

import numpy as np

# 3차원 데이터(300, 100, 100)를 2차원(300, 10,000)으로 변경
fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1, 100*100)

# K-Means 클러스터링 진행
from sklearn.cluster import KMeans

km = KMeans(n_clusters=3, random_state=42)
km.fit(fruits_2d)
```
* K-Means 클래스 객체를 이용해 K-Means 클러스터링을 할 수 있다.
* 지도 학습과 다르게 비지도 학습이므로 fit 메서드에 target data를 사용하지 않는다.
<br>              

```python
# 군집 결과 출력
print(km.labels_)
>>> 
[2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 ]

# label 종류 및 개수 출력
print(np.unique(km.labels_, return_counts=True))
>>> (array([0, 1, 2], dtype=int32), array([111,  98,  91]))
```
* 군집된 결과는 KMeans 클래스 객체의 labels_ 속성에 저장된다.
* labels_ 길이는 샘플 개수로 각 샘플이 어떤 레이블에 해당되는지 나타낸다.
* unique 메서드를 이용해 label의 종류와 개수를 알 수 있다.
<br>            

```python
# 클러스터 중심 출력
print(km.cluster_centers_)

# 클러스터 중심까지 거리 변환
print(km.transform(fruits_2d[100:101]))
>>> [[3393.8136117  8837.37750892 5267.70439881]]

# 클러스 중심 예측
print(km.predict(fruits_2d[100:101]))
>>> [0]

# 반복 횟수 출력
print(km.n_iter_)
>>> 4
```
* kMeans 클래스가 최종적으로 찾은 클러스터 중심은 cluster_centers_속성에 저장되어 있다.
* kMeans 클래스는 transform 메서드를 통해 훈련 데이터 샘플에서 클러스터 중심까지 거리를 변환해준다. 이는 특성값을 변환하는 도구로 사용할 수 있다.
  * 해당 코드는 0번 클러스터와 가까운 것을 알 수 있다.
* kMeans 클래스는 predict() 메서드를 통해 가장 가까운 클러스터 중심을 예측 클래스로 출력해준다.
  * 해당 코드는 0번 클러스터와 가장 가깝기 때문에 예측값도 0번을 출력한다.
* kMeans 알고리즘이 반복된 횟수는 n_iter 속성에 저장되어 있다.
  * 해당 코드는 클러스터 중심을 4번 옮기면서 최적의 클러스터를 찾은 걸 알 수 있다.
* 클러스터 중심을 특성 공학처럼 사용해 데이터셋을 저차원으로 변환할 수 있다.(알고리즘 속도 향상)
* 또는, 가장 가까운 거리에 있는 클러스터 중심을 샘플의 예측값으로 사용할 수 있다.
<br>              

#### 최적의 클러스터 K 찾기
* KMeans 알고리즘의 단점: 클러스터의 개수(K)를 미리 지정해야 한다.
* 최적의 K 값을 찾는 방법
  * 엘보우 방법: 클러스터 개수를 늘려가면서 이너셔의 변화를 관찰하여 최적의 클러스터 개수를 찾는 방법
  * 이너셔(inertia): 클러스터 중심과 클러스터에 속한 샘플 사이의 거리 제곱 합
  * 이너셔는 클러스터에 속한 샘플이 얼마나 가깝게 모여 있는지를 나타내는 값으로, 클러스터 개수가 늘어나면 클러스터 개개의 크기는 줄어들기 때문에 이너셔는 감소한다.
  * 클러스터 개수를 증가시키면서 이너셔를 그래프로 그리면 감소하는 속도가 꺾이는 지점을 최적의 클러스터 개수로 정한다.                         
  ![photo 69](/assets/img/blog/img69.png)                   
<br>               

#### 이너셔 그래프 시각화
```python
inertia = []
for k in range(2, 7):
    km = KMeans(n_clusters=k, n_init='auto', random_state=42)
    km.fit(fruits_2d)
    inertia.append(km.inertia_)

plt.plot(range(2, 7), inertia)
plt.xlabel('k')
plt.ylabel('inertia')
plt.show()
```
![photo 70](/assets/img/blog/img70.png)                          
* KMeans 클래스는 자동으로 이너셔를 계산해서 inertia_ 속성으로 제공한다.
* 반복문을 통해 클러스터의 개수를 증가시킨 모델을 학습하고 해당 모델의 이너셔값을 리스트에 추가한 뒤, 해당 값을 그래프로 시각화하면 다음과 같은 그래프를 얻을 수 있다. 
* 해당 그래프는 k=3이 엘보우 지점이자 최적의 클러스터 개수다.
<br>                 

#### 주성분 분석


