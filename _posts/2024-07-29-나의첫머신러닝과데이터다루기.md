---
layout: single
title:  "나의 첫 머신러닝 & 데이터 다루기"
---

## 1. 나의 첫 머신러닝 & 데이터 다루기
### 1-1 인공지능과 머신러닝, 딥러닝
* 인공지능(Artificial Intelligence): 사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술.
  * 강인공지능(Strong AI): 사람과 구분하기 어려운 지능을 가진 컴퓨터 시스,템
  * 약인공지능(Weak AI): 특정 분야에서 사람의 일을 도와주는 보조 역할을 하는 인공지능.                    
<br>                         
* 머신러닝: 데이터에서 규칙을 자동으로 학습하는 알고리즘을 연구하는 분야.
* 머신러닝 라이브러리: 사이킷런(scikit-learn)
* 사이킷런(scikit-learn) 특징
	* 파이썬 API를 사용하므로 사용하기 편리하고 컴파일하지 않아도 된다.
	* 안정적이고 성능이 검증된 머신러닝 알고리즘이 포함되어 있다.                          
<br>                                   
* 딥러닝: 머신러닝 알고리즘 중 인공 신경망을 기반으로 한 방법들
* 딥러닝 라이브러리: 텐서플로(Tensorflow), 파이토치(PyTorch)
* 딥러닝 라이브러리 특징
	* 인공 신경망 알고리즘을 전문으로 다루고 있다.
	* 파이썬 API를 제공해 사용하기 쉽다.
                                      
### 1-2. 머신러닝 키워드
* 분류(Classification): 여러 개의 종류(Class) 중 하나를 구별해 내는 문제
  * 이진 분류(Binary Classification): 2개의 클래스 중 하나를 고르는 문제
  * 다중 분류(Multi Classification): 3개 이상의 클래스 중 하나를 고르는 문제
* 특성(feature): 데이터의 특징           
<br>                                  
* 머신러닝 알고리즘
	* 지도 학습: input data와 target data(정답)으로 이루어진 훈련 데이터을 이용해 알고리즘이 target을 맞히는 것을 학습한다.
	* 비지도 학습: target data 없이 input 데이터만 사용하여 데이터의 특징 파악하고 변형하는데 도움을 준다.
	* 강화학습: target이 아닌 알고리즘이 행동한 결과로 얻은 보상을 사용해 학습한다.                   
<br>                                  
* 훈련 세트와 테스트 세트
머신러닝 알고리즘의 성능을 제대로 평가하기 위해서는 훈련 데이터와 평가에 사용할 데이터가 달라야 한다. 훈련에 사용한 데이터로 모델을 평가한다면 모델의 정확도가 매우 높아져 성능을 제대로 측정할 수 없다.
  * 훈련 세트(training set): 훈련에 사용되는 데이터, 훈련 세트로 fit 메서드를 사용해 모델 훈련
  * 테스트 세트(test set): 평가에 사용하는 데이터, socre() 메서드를 사용해 모델 평가                        
<br>                            
* 샘플(Sample): 하나의 데이터
* 샘플링 편향(Sampling bias): 훈련 세트와 테스트 세트에 샘플이 골고루 섞여 있지 않아 샘플링이 한쪽으로 치우쳐진 것으로 특정 종류의 샘플이 과도하게 많은 샘플링 편향을 가지고 있다면 제대로 된 지도 학습 모델을 만들 수 없다.         
<br>                                     
* 데이터 전처리: 머신러닝 모델에 훈련 데이터를 주입하기 전 가공하는 단계             

### 1-3 생선 데이터를 활용한 도미, 빙어 분류 문제
```python
# 도미, 빙어 데이터 준비
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]
smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

# 도미, 빙어 데이터 시각화
plt.scatter(bream_length, bream_weight)
plt.scatter(smelt_length, smelt_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
# 사진
```python
# numpy를 이용한 데이터 가공
import numpy as np
fish_data = np.column_stack((fish_length, fish_weight))
fish_target = np.concatenate((np.ones(35), np.zeros(14))
'''

```python
# 사이킷런으로 훈련 세트와 테스트 세트 나누기
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(
    fish_data, fish_target, stratify=fish_target, random_state=42)
'''

```python
# KNeighborsClassifier 모델링
kn = KNeighborsClassifier(n_neighbors=5)
kn.fit(fish_data, fish_target)
'''

```python
# Model 평가
kn.score(fish_data, fish_target)
'''

```python
# New Instance 예측 및 시각화
kn.predict([[25, 150]])

plt.scatter(train_input[:,0], train_input[:,1])
plt.scatter(25, 150, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
'''











