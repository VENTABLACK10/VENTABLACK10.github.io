---
layout: single
title:  "C4W1_C4W2"
---

## 1. Foundations of Convolutional Neural Networks

### 1.1 Computer Vision
* 컴퓨터 비전: 딥러닝과 함께 발전하고 있는 분야로 컴퓨터가 이미지나 비디오와 같은 시각적 데이터를 인식하고 해석할 수 있도록 하는 기술이다.
* 컴퓨터 비전에서 딥러닝에 관심이 가는 2가지 이유
  1. 컴퓨터 비전의 빠른 발전이 새로운 application을 만든다.
  2. 컴퓨터 비전 시스템을 구축하지 않더라도 이를 연구하는 사회가 창의적이고 도전적이며 새로운 신경망 구조와 알고리즘이 서로 많은 영감을 주면서 서로에 영향을 끼친다.
* Computer Vision Problems
  1. Image Classification(이미지 분류, 인식): 특정 크기의 사진을 입력한 뒤 사진의 물체를 알아내는 것과 같은 작업.
  2. Object detection(물체 감지): 물체를 식별하는 것을 넘어 어느 위치에 물체가 위치하는 지도 파악.
  3. Neural Style Transfer(신경망 스타일 변형): 신경망을 이용해  하나의 사진을 또 다른 사진의 스타일로 그리고 싶을 때 사용.
* Deep Learning on large images
  1. 컴퓨터 비전 문제의 방해요소는 입력이 매우 클 수 있다. 이미지의 크기 및 해상도가 커지면 입력값은 기하급수적으로 커진다.
  2. 입력값은 차원으로 이어지며 표준 완전 연결 신경망을 사용하면 변수는 더 크게 늘어난다. 변수의 수가 많으면 충분한 데이터를 얻어 과적합을 방지하기 어렵다,. 또한, 계산과 메모리의 요구사항이 많은 양의 변수를 학습하기에 적합하지 않을 수 있다.
  3. 하지만, 합성곱 연산을 구현하면 computer vision application은 이미지 크기에 대한 고민을 하지 않아도 된다.

### 1.2	Edge Detection Examples
* 컴퓨터가 물체를 인식할 때는 합성공 연산을 이용해 이미지에서 수직인 모서리(Vertical edges) 세로선과 수평의 모서리(Horizontal edges) 가로선을 감지한다.
* 이미지 행렬과 filter(kernel) 행렬의 합성공 연산을 이용해 Vertical edge detection or Horizontal edge detection             
![photo 74](/assets/img/blog/img74.png)              

### 1.3	More Edge Detection
* Vertical edge detection                          
![photo 75](/assets/img/blog/img75.png)                   
* 왼쪽에서부터 순서대로 이미지 행렬, filter(kernel) 행렬, 새로운 이미지 행렬을 의미한다.
* 이미지 행렬의 경계를 필터와의 합성공 연산을 통해 경계를 더 뚜렸하게 만들 수 있다.
<br>            
* Horizontal edges detection
* Vertical edge detection과 동일하나 아래와 같은 필터 합성곱 연산을 통해 수평선을 탐지한다.            
![photo 76](/assets/img/blog/img76.png)                
<br>      
* filter 종류
  1. Sobel filter          
  ![photo 77](/assets/img/blog/img77.png)                 
  2. Scharr filter                   
  ![photo 78](/assets/img/blog/img78.png)               
<br>
* 다양한 필터 및 통계 자료를 바탕으로 한 수동으로 만든 필터 등을 통해 더 좋은 필터를 학습 시킬 수 있다.
* 이에 따라, 가로 윤곽선, 세로 윤곽선, 기울어진 연곽선 등 다양하게 검출 가능하다.
* 위의 예시 윤곽선은 두껍게 나타난 것처럼 보이지만, 실제 이미지는 이보다 더 크기 때문에 정교한 경계선을 찾아낼 수 있다.

### 1.4	Padding 
* 기존 합성곱 연산의 단점
  1. 합성곱 연산을 진행할 때마다 이미지가 축소된다.
  2. 가장자리의 픽셀은 한 번만 사용되어 이미지 가장 자리의 정보를 적게 반영한다.
* Padding(패딩): 기존 합성곱 연산의 단점을 보완하기 위해 기존 픽셀의 원하는 픽셀만큼을 덧대는 방법이다. 패딩을 이용하면 기존의 이미지 크기를 유지하면서 가장자리의 정보를 더 가져올 수 있다.                      
![photo 78](/assets/img/blog/img78.png)                              
* Padding 종류
  1. Valid convolutions(유효 합성곱): padding 없이 합성을 진행하는 것을 의미한다.
    ex) n x n 이미지를 f x f 필터와 합성곱을 하면 (n - f + 1) x (n - f + 1) 크기의 결과 이미지 생성
  2. Same convolutions(동일 합성곱): padding을 이용해 합성곱 결과 이미지와 기존 이미지의 크기가 동일한 것을 의미한다.
    ex) n x n 이미지를 p 픽셀만큼 패딩하여 f x f 필터와 합성곱을 하면 (n + 2p - f + 1) x ((n + 2p - f + 1) 크기의 결과 이미지 생성              
      기존 이미지와 동일한 크기임을 보이기 위해 n + 2p - f + 1 = n 식을 풀면 p = (f - 1) / 2가 된다. 즉, f가 홀수일 때 p를 설정하여 기존 이미지의 크기와 같아질 수 있다.
* filter가 (홀수) x (홀수)인 이유 : 짝수도 가능은 하나 일반적으로 홀수를 사용한다.
  1. 홀수일 때 합성곱에서 동일한 크기로 패딩을 더해줄 수 있고 짝수로 설정하면 왼쪽 오른쪽을 서로 다르게 패딩해줘야 한다.
  2. 홀수 크기의 필터는 중심 위치의 중심 픽셀을 이용해 필터의 위치로 사용될 수 있기 때문이다.
  
### 1.5	Strided Convolutions
* Strided Convolutions: 합성곱 연산을 수행할 때 1칸씩 이동하는 것이 아닌 s칸씩 이동하여 합성곱 연산을 수행하는 것을 의미한다.      
![photo 80](/assets/img/blog/img80.png)                                 
* Padding과 Strided Convolutions은 다음과 같은 관계식을 가진다.
  n x n 이미지를 f x f 필터로 합성곱할 때 padding p와 stride s가 있다면,
  결과 행렬의 크기는 [{(n + 2p - f) / s} + 1] x [{(n + 2p - f) / s} + 1]
  
### 1.6	Convolutions Over Volumes
합성곱 연산은 2D 이미지뿐만 아니라 3D 이미지에도 적용 가능하다.         
![photo 81](/assets/img/blog/img81.png)                              
* 위 사진의 입력 Feature Map은 6 x 6 x 3 크기를 가진다. 여기서 3은 채널을 의미하고 RGB 이미지의 3개의 색상 채널로도 볼 수 있다.
* 3D 이미지도 윤관석 검출이나 이미지의 다른 특성을 알기 위해서는 3D 필터를 사용한다. 위의 사진과 같이 3 x 3 x 3 크기의 필터를 가진다.
* 입력 이미지의 채널과 필터의 채널은 반드시 동일해야 한다.
* 3D 이미지의 합성곱 연산도 기존 합성곱 연산과 동일하다. 채널이 3이라면 각 채널에 대해 합성곱을 한 뒤, 모두 더해주면 된다.
* 특정 윤곽선을 검출하기 위해 여러 개의 필터를 사용해서 출력 이미지의 채널을 결정한다.
  * 이에 따라 가로와 세로 윤곽선처럼 두 개의 특성 또는 10개, 128개, 수 백개의 특성들을 검출할 수 있다. 즉, 검출하고자 하는 특성의 수만큼 채널을 가지게 될 것이다.
  * stride와 padding이 없다는 가정 하에 n x n x nc 크기를 가진 입력 이미지와 f x f x nc 크기를 가진 필터가 있다면,
    결과 이미지는 (n - f + 1) x (n - f + 1) x nc' 크기를 가진다. (nc'는 사용한 필터의 개수를 의미)

### 1.7	One Layer of a Convolutional Net
* 이미지와 필터를 합성곱한 결과를 합성곱 신경망 층으로 만들기 위해서는 편향(bias)을 더해주고 ReLu 함수와 같은 비선형성을 적용해주어야 한다.
* 합성곱 신경망 층의 매개변수(parameter) 계산 방법: (신경망 계층의 크기 + 편향(bias)) x 필터 개수
  ex) 10개의 필터, 3 x 3 x 3 크기로 신경망의 한 계층에 있다면 이 층의 매개변수는 (27 + 1) x 10 = 280개
* 입력 이미지의 크기와 변수는 상관이 없다. 아주 큰 이미지라도 적은 수의 필터의 개수만큼 여러 가지 다른 속성들을 검출할 수 있다. 해당 합성곱의 성질을 이용해 과대적합을 방지할 수 있다.
* 합성곱 계층을 설명하는 notation
  1. l: 합성곱 계층을 의미하고 [l]은 특정 계층 l을 나타내는 표현이다.
  2. f^[l]: 필터의 크기를 의미한다. 특정 합성곱 계층 필터의 크기가 f x f 라는 것을 나타낸다.
  3. p^[l]: 패딩의 양을 의미한다.
  4. s^[l]: stride
  5. n_c^[l]: 필터의 개수
  6. 각 필터의 크기: f^[l] x f^[l] x n_C^[l-1]
  7. 편향과 비선형성을 적용한 뒤의 출력인 계층의 활성화 값 Activations: a^[l] = n_H^[l] × n_W^[l] × n_C^[l]
    * 배치 경사 하강법 or 미니 배치 경사하강법 사용 시, A^[l] = m x n_H^[l] × n_W^[l] × n_C^[l]
  8. Weights(가중치): f^[l] x f^[l] x n_C^[l - 1] x n_C^[l]
    * 가중치의 개수는 필터를 전부 모은 것이므로 필터의 개수만큼 곱해준다.
  9. bias(편향): 필터마다 하나의 실수값인 편향을 가지기 때문에 n_C^[l] 개수 만큼 존재
  10. Input: n_H^[l-1] x n_W^[l-1] x n_c^[l-1] (n_H: 높이, n_W: 너비, n_c: 채널)
  11. Ouput: n_H^[l] x n_W^[l] x n_c^[l]
  12. n^[l] = {(n^[l-1] + 2p^[l] - f^[l]) / s} + 1
 
### 1.8	Simple Convolutional Network Example         
![photo 82](/assets/img/blog/img82.png)                          
* 신경망층의 특징
  1. 신경망이 깊어질수록 높이와 너비가 비슷하게 유지되다가 신경망이 깊어질수록 줄어든다. 반대로 채널의 수는 늘어난다.
  2. 마지막 활성화값을 펼쳐서 하나의 벡터로 만든 뒤, 로지스틱 회귀 유닛이나 소프트맥스 유닛에 넣게 되면 신경망의 최종 예측값이 된다.
* 합성곱 신경망 층의 종류
  1. Convolution layer(신경망층)
  2. Pooling layer(풀링층)
  3. Fully connected layer(완전 연결층)
  
### 1.9	Pooling Layers
* Max pooling: 주어진 영역에서 최대값을 선택하여 픽셀의 크기를 축소하는 방법이다.                     
![photo 83](/assets/img/blog/img83.png)                                              
* 해당 사진은 2 x 2 필터(f=2)와 stride=2를 적용한 것과 동일하며 f=2와 s=2를 max pooling의 hyperparameter라고 한다.
* max pooling의 결과값을 통해 가장 큰 수가 특정 특성을 의미할 수도 있고 특성이 존재하지 않을 수도 있다.
* 일반적으로 f=2, s=2를 사용하기 때문에 높이가 너비가 절반이 된다.             
<br>   
 
* Average pooling: 주어진 영역의 평균값을 계산하여 픽셀의 크기를 축소하는 방법이다.           
![photo 84](/assets/img/blog/img84.png)          
* average pooling은 신경망의 아주 깊은 곳에서 제한적으로 활용된다.       
<br>   

* pooling 특징
  1. pooling은 hyperparameter가 있지만 고정된 값이라 학습할 수 있는 변수가 존재하지 않는다. 그래서 역전파를 적용해보면 역전파가 가능한 변수가 없다.
  2. 따라서 pooling은 hyperparameter가 정해지면 그 이상 학습할 것이 없다.
  3. filter와 stride 외에 padding을 hyperparameter로 추가할 수 있지만, max pooling에서는 거의 사용하지 않는다.
  4. max pooling input shape: n_H x n_W x n_C                
     max pooling output shape: {(n_H – f} / s} + 1 x {(n_W – f} / s} + 1 x n_C                    
     (pooling은 각 채널에 개별적으로 적용되기 때문에 입력 채널과 출력 채널이 일치한다)
     
### 1.10 CNN Example
* LeNet-5 model을 통한 CNN 특징 파악         
![photo 85](/assets/img/blog/img85.png)                       
1. 신경망이 깊어질수록 높이와 너비는 감소한다.
2. 반대로, 채널의 수는 증가한다.
3. 신경망의 흔한 패턴: 합성곱층(CONV) -> 풀링층(POOL) -> (반복) ... -> FC(완전 연결층) -> Softmax(활성화함수)              
4. Activation Size는 신경망이 깊어질수록 점점 줄어든다.
5. Parameter의 개수는 신경망이 깊어질수록 신경망 층에서 점차 증가하다 FC(완전연결층)에서 기하급수적으로 늘어났다 줄어줄고 Softmax(활성화함수)에 의해 다시 크게 감소한다.

### 1.11 Why Convolutions
* 합성곱층 사용 시 이점
  1. 변수 공유: 합성곱층에 동일한 필터를 입력 이미지 전체에 적용하기 때문에 동일한 가중치를 여러 위치에서 공유한다. 이에 따라 학습해야 할 가중치 수가 줄어들게 된다.
  2. 희소 연결: 합성곱 연산이 필터 크기 만큼의 영역에만 적용되므로 모든 입력값이 출력과 연결되지 않는다. 이에 따라 계산 비용을 줄이면서 효과적인 학습이 가능하다.
  3. 변수 공유와 희소 연결을 통해 신경망의 변수가 줄어들어 작은 훈련 세트를 가질 수 있고 과대적합도 방지할 수 있다.
  4. 합성곱 신경망은 이동 불변성을 포착할 수 있다. 몇 픽셀 이동한 이미지도 유사한 속성을 가지게 되고 동일한 결과를 얻을 수 있다. 모든 이미지의 위치에 동일한 필터를 적용하고, 초반과 이후의 층들에도 동일한 필터를 적용하기 때문에 신경망에서 자동으로 학습할 수 있다.
  5. 합성곱 신경망과 완전 연결층은 w라는 변수를 가지게 되고 편향 b를 가지는데 변수의 설정으로 비용 함수를 찾을 수 있다. 무작위로 w와 b를 초기화함으로써 비용 J(신경망의 훈련 세트에 대한 예측의 손실합을 m으로 나눈 값)를 계산할 수 있다. (따라서 신경망을 훈련시키기 위해서는 비용함수 J를 줄이기 위해 경사 하강법, 모멘트 경사 하강법, RMSprop 등 다양한 알고리즘을 사용해 변수를 최적화할 수 있다.)

## 2. Deep Convolutional Models: Case Studies

### 2.1 Classic Network
* LeNet-5 이해하기                        
![photo 86](/assets/img/blog/img86.png)              
* LeNet-5 과정
  1. 입력 이미지 크기 = 32 x 32 x 1
  2. 5 x 5 필터 6개와 stride=1을 사용 -> 28 x 28 x 6
  3. 2 x 2 필터와 stride=2를 이용한 average pooling -> 14 x 14 x 6
  4. 5 x 5 필터 16개와 stride=1을 사용 -> 10 x 10 x 16
  5. 2 x 2 필터와 stride=2를 이용한 average pooling -> 5 x 5 x 16 = 400
  6. 400개의 FC(완전 연결층) -> 84개의 FC(완전연결층) -> 비선형성 함수를 사용한 예측값
* LeNet-5 특징
  1. 깊이가 깊어질수록 높이와 너비는 감소하고 채널의 수는 증가한다
  2. <합성곱층 -> 풀링층 -> 합성곱층 -> 풀링층 -> 완전연결층 -> 출력> 패턴
  3. 비선형성 함수로 Relu를 사용하지 않고 tanh와 sigmoid 사용
  4. LeNet-5 목적: 손글씨의 숫자 인식
<br>      
* AlexNet 이해하기                     
![photo 87](/assets/img/blog/img87.png)                 
* AlexNet 과정
  1. 입력 이미지 크기 = 227 x 227 x 3
  2. 11 x 11 필터 96개와 stride=4을 사용 -> 55 x 55 x 96
  3. 3 x 3 필터와 stride=2를 이용한 max pooling -> 27 x 27 x 96
  4. 5 x 5의 동일 합성곱 연산 실행 -> 27 x 27 x 256
  5. 3 x 3 필터와 stride=2를 이용한 max pooling -> 13 x 13 x 256
  6. 3 x 3의 동일 합성곱 연산 실행 -> 13 x 13 x 384
  7. 3 x 3의 동일 합성곱 연산 실행 -> 13 x 13 x 384
  8. 3 x 3의 동일 합성곱 연산 실행 -> 13 x 13 x 256
  9. 3 x 3 필터와 stride=2를 이용한 max pooling -> 6 x 6 x 256 = 9216
  10. 9216개의 FC(완전 연결층) -> 4096개의 FC(완전연결층) -> 4096개의 FC(완전연결층)
  11. softmax를 사용해 1000개의 예측값 출력
* LeNet-5 특징
  1. LeNet과 매우 유사하지만 훨씬 큰 크기를 가진다. (LeNet 매개변수: 6만 개 / AlexNet 매개변수: 6천만 개)
  2. 더 많은 은닉 유닛과 더 많은 데이터를 통해 훈련하기 때문에 훨씬 더 뛰어난 성능을 보인다.
  3. Reulu 활성화 함수를 사용한다.
<br>     
* VGG-16  이해하기                
![photo 88](/assets/img/blog/img88.png)              
* VGG-16 과정
  1. 입력 이미지 크기 = 224 x 224 x 3 2개
  2. 64개의 필터를 가진 2개의 합성곱층에 동일 합성곱 진행 -> 224 x 224 x 64 (2개, [CONV 64] X 2])
  3. 2 x 2 필터와 stride=2을 이용한 max pooling -> 112 x 112 x 64
  4. 128개의 필터를 가진 2개의 합성곱층에 동일 합성곱 진행 -> 112 x 112 x 128
  5. 2 x 2 필터와 stride=2을 이용한 max pooling -> 56 x 56 x 128
  6. 256개의 필터를 가진 3개의 합성곱층에 동일 합성곱 진행 -> 56 x 56 x 256
  7. 2 x 2 필터와 stride=2을 이용한 max pooling -> 28 x 28 x 256
  8. 512개의 필터를 가진 3개의 합성곱층에 동일 합성곱 진행 -> 28 x 28 x 512
  9. 2 x 2 필터와 stride=2을 이용한 max pooling -> 14 x 14 x 512
  10. 512개의 필터를 가진 3개의 합성곱층에 동일 합성곱 진행 -> 14 x 14 x 512
  11. 2 x 2 필터와 stride=2을 이용한 max pooling -> 7 x 7 x 512
  12. 4096개의 FC(완전 연결층) -> 4096개의 FC(완전연결층)
  13. softmax를 사용해 1000개의 예측값 출력
* VGG-16 특징
  1. 합성곱에서 stride가 1인 3 x 3 필터만을 사용해 동일 합성곱을 진행한다.
  2. max pooling에서는 2 x 2 필터와 stride=2만을 이용한다.
  3. 많은 하이퍼파라미터를 가지지만 비교적 간결한 구조를 가진다.
  4. 신경망의 깊이가 깊어질수록 풀링층에서는 높이가 너비가 매번 절반으로 줄어든다.
  5. 신경망의 깊이가 깊어질수록 합성곱층에서는 채널의 수가 매번 두 배 가량 늘어난다.
  6. VGG-16의 16이라는 숫자는 16개의 가중치를 가진 층이 있다는 것을 의미한다.
  7. VGG-16dms 1억 3천 8백만 개 정도의 변수를 가진 큰 네트워크다.

### 2.2 Resnets
 
### 2.3 Why ResNets Work

### 2.4 Network In Network

### 2.5 Inception Network Motivation

### 2.6 Inception Network

### 2.7 Transfer Learning

### 2.8 Data Augmentation

