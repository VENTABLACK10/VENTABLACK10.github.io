{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1062bd-f397-47d9-b93f-621098d38512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Init\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# list -> tensor\n",
    "arr = [1,2]\n",
    "tensor = torch.tensor(arr)\n",
    "\n",
    "# float -> tensor\n",
    "val = 2.0\n",
    "tensor = torch.tensor(val)\n",
    "\n",
    "# numpy -> tensor \n",
    "import numpy as np\n",
    "np_arr = np.array([1,2])\n",
    "x_t = torch.from_numpy(np_arr)\n",
    "\n",
    "# 2x3 tensor of zeros\n",
    "zeros_t = torch.zeros((2,3))\n",
    "# 2x3 tensor of ones\n",
    "ones_t = torch.ones((2,3)) \n",
    "# 2x3 tensor of random numbers\n",
    "rand_t = torch.randn((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3e372d-ba1c-4f88-83b0-b0217c57c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Attributes\n",
    "\n",
    "# torch size\n",
    "zeros_t.shape\n",
    "\n",
    "# torch type\n",
    "x_t = torch.tensor(2.0)\n",
    "x_t.dtype\n",
    "\n",
    "# 해당 텐서의 할당 장치 확인\n",
    "arr = [1,2]\n",
    "x_t = torch.tensor(arr, dtype=torch.float32)\n",
    "x_t.device\n",
    "\n",
    "# tesnsor 속성 수정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "arr = [1,2]\n",
    "x_t = torch.tensor(arr, dtype=torch.float32, device=device)\n",
    "x_t = x_t.to(device, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500eef5d-04e0-49ab-aadf-3c171db0d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operations\n",
    "\n",
    "# scalar mul\n",
    "c = 10\n",
    "x_t = x_t*c\n",
    "\n",
    "# sum, element wise-sum (sub 동일)\n",
    "x1_t = torch.zeros((1,2))\n",
    "x2_t = torch.ones((1,2))\n",
    "x1_t + x2_t\n",
    "\n",
    "# mul\n",
    "x1_t = torch.tensor([[1,2],[3,4]])\n",
    "x2_t = torch.tensor([[1,2,3],[4,5,6]])\n",
    "torch.matmul(x1_t, x2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6cf1e-a03a-4427-896c-dcf1fc010253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients(f의 편미분값 계산)\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "z = torch.tensor(1.5, requires_grad=True)\n",
    "f = x**2+y**2+z**2\n",
    "f.backward()\n",
    "x.grad, y.grad, z.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3d2a8-69dd-4f0b-9937-09fbf788bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn module -> 모델 정의, 훈련, 테스트 관련 기본 기능 제공\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "in_dim, out_dim = 256, 10 # 입력 차원, 출력 차원 설정\n",
    "vec = torch.randn(256)\n",
    "layer = nn.Linear(in_dim, out_dim, bias=True) # 단일 레이어 정의\n",
    "out = layer(vec)\n",
    "\n",
    "W = torch.rand(10,256) # 행렬 W\n",
    "b = torch.zeros(10,1) # 편향 벡터 b\n",
    "out = torch.matmul(W, vec) + b\n",
    "\n",
    "in_dim, feature_dim, out_dim = 784, 256, 10\n",
    "vec = torch.randn(784)\n",
    "layer1 = nn.Linear(in_dim, feature_dim, bias=True)\n",
    "layer2 = nn.Linear(feature_dim, out_dim, bias=True)\n",
    "out = layer2(layer1(vec))\n",
    "\n",
    "relu = nn.ReLU() # 비선형 함수 추가를 ReLU 활용\n",
    "out = layer2(relu(layer1(vec)))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c52c89-852b-4881-b9dd-5c1e52aded7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClassifier(nn.Module):\n",
    "  def __init__(self, in_dim, feature_dim, out_dim):\n",
    "    super(BaseClassifier, self).__init__()\n",
    "    self.layer1 = nn.Linear(in_dim, feature_dim, bias=True)\n",
    "    self.layer2 = nn.Linear(feature_dim, out_dim, bias=True)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  # 분류기\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.relu(x)\n",
    "    out = self.layer2(x)\n",
    "    return out\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f878da-a39f-4447-a3ac-e1d39863a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer: 기울기 기반 파라미터 조정\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=lr)\n",
    "\n",
    "optimizer.step() # Updates parameters via SGD\n",
    "optimizer.zero_grad() # Zeroes out gradients between minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b3cce-ea4f-4de5-92bd-4dcac11e6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Dataset Load\n",
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, img_dir, label_file):\n",
    "    super(ImageDataset, self).__init__()\n",
    "    self.img_dir = img_dir\n",
    "    self.labels = torch.tensor(np.load(label_file, allow_pickle=True))\n",
    "    self.transforms = transforms.ToTensor()\n",
    "\n",
    "  # index를 입력으로 받아 해당 index의 예시를 반환\n",
    "  def __getitem__(self, idx):\n",
    "    img_pth = os.path.join(self.img_dir, \"img_{}.jpg\".format(idx))\n",
    "    img = Image.open(img_pth)\n",
    "    img = self.transforms(img).flatten()\n",
    "    label = self.labels[idx]\n",
    "    return {\"data\":img, \"label\":label}\n",
    "      \n",
    "  # dataset의 길이, 모델을 훈련 or 테스트할 예시 데이터의 수를 의미\n",
    "  def __len__(self):\n",
    "    return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82108199-9fbf-4d0d-ac29-75c70754a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(img_dir='./data/train/',\n",
    "                             label_file='./data/train/labels.npy')\n",
    "\n",
    "# DataLoader: 데이터셋 인스턴스화를 입력으로 사용\n",
    "# 미니배치에 의해 데이터셋에 로드하고 epoch 간에 dataset을 shuffle\n",
    "# Python의 다중 처리 내장 모듈을 사용하여 미니배치를 병렬로 효율적으로 사용\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=4, \n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6df72-70ec-4c6d-a84a-265932ef7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 분류기 생성\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class BaseClassifier(nn.Module):\n",
    "  def __init__(self, in_dim, feature_dim, out_dim):\n",
    "    super(BaseClassifier, self).__init__()\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Linear(in_dim, feature_dim, bias=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(feature_dim, out_dim, bias=True)\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.classifier(x)\n",
    "    \n",
    "\n",
    "# MNIST 데이터셋을 로드한다.\n",
    "train_dataset = MNIST(\".\", train=True, \n",
    "                      download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(\".\", train=False, \n",
    "                     download=True, transform=ToTensor())\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=64, shuffle=False)\n",
    "\n",
    "# model, optimizer, hyperparameter를 인스턴스화한다.\n",
    "in_dim, feature_dim, out_dim = 784, 256, 10\n",
    "lr=1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs=40\n",
    "classifier = BaseClassifier(in_dim, feature_dim, out_dim)\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=lr)\n",
    "\n",
    "def train(classifier=classifier,\n",
    "          optimizer=optimizer,\n",
    "          epochs=epochs,\n",
    "          loss_fn=loss_fn):\n",
    "\n",
    "  classifier.train()\n",
    "  loss_lt = []\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for minibatch in train_loader:\n",
    "      data, target = minibatch\n",
    "      data = data.flatten(start_dim=1)\n",
    "      out = classifier(data)\n",
    "      computed_loss = loss_fn(out, target)\n",
    "      computed_loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 각 미니배치 손실 합 기록\n",
    "      running_loss += computed_loss.item()\n",
    "    loss_lt.append(running_loss/len(train_loader))\n",
    "    print(\"Epoch: {} train loss: {}\".format(epoch+1, running_loss/len(train_loader)))\n",
    "\n",
    "  plt.plot([i for i in range(1,epochs+1)], loss_lt)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Training Loss\")\n",
    "  plt.title(\n",
    "      \"MNIST Training Loss: optimizer {}, lr {}\".format(\"SGD\", lr))\n",
    "  plt.show()\n",
    "\n",
    "  # checkpoint state 저장\n",
    "  torch.save(classifier.state_dict(), 'mnist.pt')\n",
    "\n",
    "def test(classifier=classifier, \n",
    "          loss_fn = loss_fn):\n",
    "  classifier.eval()\n",
    "  accuracy = 0.0\n",
    "  computed_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "          data = data.flatten(start_dim=1)\n",
    "          out = classifier(data)\n",
    "          _, preds = out.max(dim=1)\n",
    "\n",
    "          # loss and accuracy 계산\n",
    "          computed_loss += loss_fn(out, target)\n",
    "          accuracy += torch.sum(preds==target)\n",
    "          \n",
    "      print(\"Test loss: {}, test accuracy: {}\".format(\n",
    "          computed_loss.item()/(len(test_loader)*64), accuracy*100.0/(len(test_loader)*64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6e97a-2285-42aa-bb75-c7174f597b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10을 위한 합성공 신경망 구축\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128,10),\n",
    "            nn.BatchNorm1d(10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        return self.block2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecda5fe-131c-4a89-a6b4-b897754ed26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet34 아키텍쳐 구현\n",
    "\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "model = resnet34()\n",
    "\n",
    "# 2재의 합성공 layer로 구성\n",
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, in_layers, out_layers, downsample=None):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_layers, out_layers,\n",
    "                           kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(out_layers)\n",
    "    self.conv2 = nn.Conv2d(out_layers, out_layers,\n",
    "                           kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(out_layers)\n",
    "    self.downsample = downsample\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "  def forward(self, inp):\n",
    "    # Residual block\n",
    "    out = self.conv1(inp)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)\n",
    "    \n",
    "    if self.downsample: \n",
    "      inp = self.downsample(inp)\n",
    "    \n",
    "    # 단축 연결\n",
    "    out += inp\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af8153-c11c-4a91-85f6-2ec0e1108586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ResNet34, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Sequential(\n",
    "      nn.Conv2d(3, 64, kernel_size=7,\n",
    "                stride=2, padding=3, bias=False),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=3,\n",
    "                   stride=2, padding=1)\n",
    "    )\n",
    "\n",
    "    # 각 Residual Block은 convolution layer를 2개씩 가진다.\n",
    "    # 연속  3개의 block, 6개의 convolution layer\n",
    "    self.comp1 = nn.Sequential(\n",
    "      ResidualBlock(64, 64),\n",
    "      ResidualBlock(64, 64),\n",
    "      ResidualBlock(64, 64)\n",
    "    )\n",
    "\n",
    "     # 연속 4개의 block, 8개의 convolution layer\n",
    "    downsample1 = nn.Sequential(\n",
    "      nn.Conv2d(64, 128, kernel_size=1,\n",
    "             stride=1, bias=False),\n",
    "      nn.BatchNorm2d(128)\n",
    "    )\n",
    "    self.comp2 = nn.Sequential(\n",
    "      ResidualBlock(64, 128, downsample=downsample1),\n",
    "      ResidualBlock(128, 128),\n",
    "      ResidualBlock(128, 128),\n",
    "      ResidualBlock(128, 128)\n",
    "    )\n",
    "    \n",
    "    # 연속 6개의 block, 12개의 convolution layer\n",
    "    downsample2 = nn.Sequential(\n",
    "      nn.Conv2d(128, 256, kernel_size=1, stride=1, bias=False),\n",
    "      nn.BatchNorm2d(256)\n",
    "    )\n",
    "    self.comp3 = nn.Sequential(\n",
    "      ResidualBlock(128, 256, downsample=downsample2),\n",
    "      ResidualBlock(256, 256),\n",
    "      ResidualBlock(256, 256),\n",
    "      ResidualBlock(256, 256),\n",
    "      ResidualBlock(256, 256),\n",
    "      ResidualBlock(256, 256),\n",
    "    )\n",
    "    \n",
    "    # 연속 3개의 block, 6개의 convolution layer\n",
    "    downsample3 = nn.Sequential(\n",
    "      nn.Conv2d(256, 512, kernel_size=1, stride=1, bias=False),\n",
    "      nn.BatchNorm2d(512)\n",
    "    )\n",
    "    self.comp4 = nn.Sequential(\n",
    "      ResidualBlock(256, 512, downsample=downsample3),\n",
    "      ResidualBlock(512, 512),\n",
    "      ResidualBlock(512, 512)   \n",
    "    )\n",
    "\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    # ImageNet classifier: 1000 classes\n",
    "    self.fc = nn.Linear(512, 1000)\n",
    "\n",
    "  def forward(self, inp):\n",
    "    out = self.conv1(inp)\n",
    "    \n",
    "    out = self.comp1(out)\n",
    "    out = self.comp2(out)\n",
    "    out = self.comp3(out)\n",
    "    out = self.comp4(out)\n",
    "\n",
    "    out = self.avgpool(out)\n",
    "    out = torch.flatten(out, 1)\n",
    "    out = self.fc(out)\n",
    "\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
