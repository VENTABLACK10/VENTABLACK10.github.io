{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Code Review_Version1** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Backbone : VGG16** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORmjcHlT-Qgm"
   },
   "source": [
    "## **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReeHrtxm-LYC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajdGNW55-WUN"
   },
   "source": [
    "## **Define Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnrVUVGl-ZGr"
   },
   "outputs": [],
   "source": [
    "\"\"\"# **1) Model define**\n",
    "### trans_VGG에서 사용할 함수인 conv_2 define\n",
    "\"\"\"\n",
    "\n",
    "def conv_2(in_dim, out_dim):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),# Model define\n",
    "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def conv_3(in_dim, out_dim):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),# Model define\n",
    "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_2 함수 : 2개의 합성곱 레이어와 Relu 활성화 함수로 구성된 block 정의 후 max pooling을 통해 크기 감소\n",
    "# conv_3 함수 : 4개의 합성곱 레이어와 Relu 활성화 함수로 구성된 block 정의 후 max pooling을 통해 크기 감소\n",
    "# Conv2d(): 3 x 3 필터(커널), padding=1 인 2차원 합성곱 레이어\n",
    "# Relu(): 활성화 함수 Relu를 통해 비선형성 추가\n",
    "# MaxPool2d(): max pooling을 통해 입력값의 크기를 절반으로 줄임\n",
    "\n",
    "# 과적합 방지를 위한 Dropout 제안\n",
    "# 이미지의 크기가 감소하는 특징 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtjKQ3Ss-eOM"
   },
   "source": [
    "## **Define trans_VGG class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Ty-Lx7--jv0"
   },
   "outputs": [],
   "source": [
    "class trans_VGG(nn.Module):\n",
    "    def __init__(self, base_dim):\n",
    "        super(trans_VGG, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            conv_2(3, base_dim),\n",
    "            conv_2(base_dim, base_dim*2),\n",
    "            conv_2(base_dim*2, base_dim*4),\n",
    "            conv_3(base_dim*4, base_dim*8),\n",
    "            conv_3(base_dim*8, base_dim*8)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(base_dim*8*7*7, base_dim*4*7*7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(base_dim*4*7*7, base_dim*2*7*7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(base_dim*2*7*7, base_dim*7*7)\n",
    "        )\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.feature -> 특성 추출\n",
    "# 차원 수가 2배씩 점차 증가하는 특징 존재\n",
    "\n",
    "# self.fc_layer -> 완전 연결층과 같이 1차원으로 펼치는 작업\n",
    "# layer의 크기를 점차 줄여가며 출력값을 생성한다.\n",
    " \n",
    "# foward 함수\n",
    "# 입력 이미지를 특성 추출 레이어에 통과시켜 특성 맵을 추출 후, 1차원 벡터로 변환\n",
    "# 변환된 벡터를 완전 연결층에 통과시켜 최종 예측을 수행하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JlwvIx9-oB3"
   },
   "source": [
    "- Hyper_paremeter : Learning rate, momentum, weight decay 등은 논문의 Hyper peremeter value로 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_79OsMOG-olp"
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "seed = time.time()\n",
    "\n",
    "def custom_init_weights(m):\n",
    "  if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "  if isinstance(m, torch.nn.Linear) and m.weight is not None:\n",
    "    init.normal_(m.weight, mean=1, std=0.01)\n",
    "    if m.bias is not None:\n",
    "      init.constant_(m.bias, 0)\n",
    "\n",
    "model = trans_VGG(base_dim=64)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "optimizer =torch.optim.SGD(model.parameters(), lr = 0.01,momentum = 0.9, weight_decay = 0.0005)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.1, verbose=True)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.RandomCrop(224)])\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_init_weights 함수\n",
    "# 모델의 각 레이어가 torch.nn.Linear 타입일 때, \n",
    "# 가중치(w)를 평균 1 표준편차 0.01인 정규분포로 초기화, 편향(b)은 0으로 초기화\n",
    "\n",
    "# trans_VGG class 객체 생성 -> 생성자에 의해 모델의 layer 설정\n",
    "\n",
    "# loss function 정의 BCELoss(): 이진 교차 엔트로피 소실 함수\n",
    "# optimizer: 확률적 경사하강법 사용, 학습률 0.01, momentum=0.9(빠른 수렴), weight_decay=0.0005: 가중치 감쇠(정규화)\n",
    "# ReduceLROnPlateau: 모델의 성능 향상이 10번의 epoch 동안 없을 때 학습률 10배 감소 + 성능 최대화 시 학습률 조정\n",
    "\n",
    "# transform: 이미지의 픽셀 값(0~255)을 0과 1 사이의 값으로 정규화 및 224 x 224 크기의 Random Crop 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDUjpjGy-wJn"
   },
   "source": [
    "## **Import Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7NWSJZD-yoP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Project 3 폴더 경로\n",
    "project_folder = '/content/drive/MyDrive/Project3'\n",
    "\n",
    "image = []\n",
    "label = []\n",
    "\n",
    "# Project 3 폴더 내부의 세부 폴더를 확인하고 이미지와 라벨 데이터 생성\n",
    "for subdir, _, files in os.walk(project_folder):\n",
    "    for file in files:\n",
    "        # 이미지 파일인지 확인\n",
    "        if file.endswith(('png', 'jpg', 'jpeg')):\n",
    "            image_path = os.path.join(subdir, file)\n",
    "            image.append(image_path)\n",
    "\n",
    "            # 이미지가 속한 세부 폴더의 이름을 라벨로 사용\n",
    "            label_name = os.path.basename(subdir)\n",
    "            label.append(label_name)\n",
    "\n",
    "indices = np.random.permutation(len(image))\n",
    "IMAGE = [image[i] for i in indices]\n",
    "LABEL = [label[i] for i in indices]\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transforms.RandomCrop(224)(image)\n",
    "        image = transforms.ToTensor()(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "TRAINING_image = []\n",
    "TRAINING_label = []\n",
    "TEST_image = []\n",
    "TEST_label = []\n",
    "\n",
    "for i in range(0,80):\n",
    "  for j in range(0,20):\n",
    "    for k in range(0,2):\n",
    "      TRAINING_image.append(image[200*j+i+k])\n",
    "      TRAINING_label.append(label[200*j+i+k])\n",
    "\n",
    "for i in range(80,100):\n",
    "  for j in range(0,20):\n",
    "    for k in range(0,2):\n",
    "      TEST_image.append(image[200*j+i+k])\n",
    "      TEST_label.append(label[200*j+i+k])\n",
    "\n",
    "train_dataset = CustomDataset(TRAINING_image, TRAINING_label, transform = transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE,num_workers=2)\n",
    "test_dataset = CustomDataset(TEST_image, TEST_label, transform = transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61PMWGKo-2dQ"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBiV7BHk-4MH"
   },
   "outputs": [],
   "source": [
    "\"\"\"# **3) TRAINING**\"\"\"\n",
    "\n",
    "EPOCH = 80 # 반복횟수\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# 시간 측정\n",
    "start_time = time.time()\n",
    "train_acc_lst, test_acc_lst = [],[]\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "  model.train() # 학습모드\n",
    "  correct_pred, num_examples = 0, 3200 # 정확하게 예측한 샘플 수 (초기값), 학습 데이터셋의 크기\n",
    "  for i, (_image1, _label1) in enumerate(train_loader): # mini-batch 반복을 통해 이미지에 대한 tensor 입력\n",
    "    image1 = _image1.to(DEVICE)\n",
    "    label1 = _label1[0]\n",
    "    vector1_tensor = model(image1)\n",
    "\n",
    "    if (i == 0): #Exception Case\n",
    "      image2 = image1\n",
    "      label2 = label1\n",
    "      vector2_tensor = vector1_tensor\n",
    "\n",
    "    # 두 이미지의 코사인 유사도 측정\n",
    "    similarity =  F.cosine_similarity(vector1_tensor, vector2_tensor, dim= -1)\n",
    "    scaled_similarity = torch.sigmoid(similarity)\n",
    "\n",
    "    # 유사도 기준 = 0.5 \n",
    "    if label1 == label2 and scaled_similarity.item() > 0.5: # 두 이미지의 라벨이 동일한 경우\n",
    "        correct_pred += 1\n",
    "    elif label1 != label2 and scaled_similarity.item() < 0.5: # 두 이미지의 라벨이 다른 경우\n",
    "        correct_pred += 1\n",
    "\n",
    "    if label1 == label2:\n",
    "      target_vector = [1]\n",
    "    else :\n",
    "      target_vector = [0]\n",
    "\n",
    "    # 역전파 및 가중치 업데이트\n",
    "    target_tensor = torch.tensor(target_vector).float()\n",
    "    target_tensor = target_tensor.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    cost = loss(scaled_similarity, target_tensor)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 40개의 batch마다 학습의 진행 상태 및 cost 출력\n",
    "    if not i % 40:\n",
    "      print (f'Epoch: {epoch:03d}/{EPOCH:03d} | '\n",
    "            f'Batch {i:03d}/{len(train_loader):03d} |'\n",
    "             f' Cost: {cost:.4f}')\n",
    "\n",
    "    #연산량 감소를 위한 텐서 재활용\n",
    "    image2 = image1.clone()\n",
    "    label2 = label1\n",
    "    vector2_tensor = vector1_tensor.detach().clone()\n",
    "\n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: VGG-model\n",
    "# 가중치 초기화 및 손실 함수, 옵티마이저 정의\n",
    "# 이미지 크기 변환 및 random crop 활용\n",
    "\n",
    "# 배치 크기 조정 및 배치 정규화 추가를 통한 성능 개선 고려\n",
    "# 옵티마이저 함수 변경을 통한 성능 개선 고려\n",
    "# 추가적인 이미지 증강 고려"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
